## replace plausible-0 with plausible, for easy filtering
data$Input.code <- gsub('plausible-0', 'plausible', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible', data$Input.code)
checksdf$filler.left <- data[data[, "Input.code"]=="filler_filler_2_NO_QUESTION",
"Answer.Rating"]
checksdf$filler.right <- data[data[, "Input.code"]=="filler_filler_1_NO_QUESTION",
"Answer.Rating"]
# separate the Input code into categories
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
# info we don't need
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
# ANALYSES
## Look at data by participant (TODO: fix avg rating for plaus and implaus)
data = data %>%
group_by(WorkerId) %>%
mutate(
na.pct = mean(is.na(Answer.Rating)),
n = length(Answer.Rating),
) %>%
ungroup()
# # To look at only AI output
# data = data %>% filter(TrialType == "AI")
data = data %>%
group_by(WorkerId, Plausibility) %>%
mutate(
avrating = mean(Answer.Rating, na.rm=TRUE)
) %>%
ungroup()
data_summ = data %>% group_by(WorkerId, Plausibility) %>%
summarize(
na.pct = mean(na.pct),
n = mean(n),
avrating = mean(avrating),
) %>%
spread(key=Plausibility, value=avrating)
data_summ = merge(data_summ, checksdf, by="WorkerId")
data_summ$diff = data_summ$plausible - data_summ$implausible
## save a summary of individual subjects' performance
write_csv(data_summ,"data_summ_by_worker_new.csv")
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4368386_batch_results_raw.csv',
'../results_raw/Batch_4332828_batch_results_raw.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
View(data)
data = do.call("rbind", data)
filenames=c('../results_raw/Batch_4368386_batch_results_raw.csv',
'../results_raw/Batch_4332828_batch_results_raw.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId'),starts_with('WorkTimeInSeconds'),
starts_with('HITId'), starts_with('AssignmentStatus'),
starts_with('AssignmentId'))
data = data %>% filter(AssignmentStatus == "Submitted")
# checksdf = data %>% select(starts_with('WorkerId'))
checksdf = data %>% select(c('WorkerId', 'Answer.English', 'Answer.country',
'Answer.proficiency1', 'Answer.proficiency2',
'WorkTimeInSeconds', 'Answer.answer', 'HITId',
'AssignmentStatus', 'AssignmentId'))
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Input.list,-Answer.country,
-Answer.English,-Answer.answer, -Answer.proficiency1,
-Answer.proficiency2, -WorkTimeInSeconds, -HITId,
-AssignmentStatus, -AssignmentId)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
data$Answer.Rating <- as.numeric(data$Answer.Rating)
## replace plausible-0 with plausible, for easy filtering
data$Input.code <- gsub('plausible-0', 'plausible', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible', data$Input.code)
checksdf$filler.left <- data[data[, "Input.code"]=="filler_filler_2_NO_QUESTION",
"Answer.Rating"]
checksdf$filler.right <- data[data[, "Input.code"]=="filler_filler_1_NO_QUESTION",
"Answer.Rating"]
# separate the Input code into categories
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
# info we don't need
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
data = data %>%
group_by(WorkerId) %>%
mutate(
na.pct = mean(is.na(Answer.Rating)),
n = length(Answer.Rating),
) %>%
ungroup()
# # To look at only AI output
# data = data %>% filter(TrialType == "AI")
data = data %>%
group_by(WorkerId, Plausibility) %>%
mutate(
avrating = mean(Answer.Rating, na.rm=TRUE)
) %>%
ungroup()
data_summ = data %>% group_by(WorkerId, Plausibility) %>%
summarize(
na.pct = mean(na.pct),
n = mean(n),
avrating = mean(avrating),
) %>%
spread(key=Plausibility, value=avrating)
data_summ = merge(data_summ, checksdf, by="WorkerId")
data_summ$diff = data_summ$plausible - data_summ$implausible
## save a summary of individual subjects' performance
write_csv(data_summ,"data_summ_by_worker_new.csv")
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4368386_batch_results_raw.csv',
'../results_raw/Batch_4332828_batch_results_raw.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
View(data)
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId'),starts_with('WorkTimeInSeconds'),
starts_with('HITId'), starts_with('AssignmentStatus'),
starts_with('AssignmentId'))
# #get only newly submitted HITs
# data = data %>% filter(AssignmentStatus == "Submitted")
# checksdf = data %>% select(starts_with('WorkerId'))
checksdf = data %>% select(c('WorkerId', 'Answer.English', 'Answer.country',
'Answer.proficiency1', 'Answer.proficiency2',
'WorkTimeInSeconds', 'Answer.answer', 'HITId',
'AssignmentStatus', 'AssignmentId'))
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Input.list,-Answer.country,
-Answer.English,-Answer.answer, -Answer.proficiency1,
-Answer.proficiency2, -WorkTimeInSeconds, -HITId,
-AssignmentStatus, -AssignmentId)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
data$Answer.Rating <- as.numeric(data$Answer.Rating)
## replace plausible-0 with plausible, for easy filtering
data$Input.code <- gsub('plausible-0', 'plausible', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible', data$Input.code)
checksdf$filler.left <- data[data[, "Input.code"]=="filler_filler_2_NO_QUESTION",
"Answer.Rating"]
checksdf$filler.right <- data[data[, "Input.code"]=="filler_filler_1_NO_QUESTION",
"Answer.Rating"]
# separate the Input code into categories
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
# info we don't need
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
# ANALYSES
data = data %>%
group_by(WorkerId) %>%
mutate(
na.pct = mean(is.na(Answer.Rating)),
n = length(Answer.Rating),
) %>%
ungroup()
# # To look at only AI output
# data = data %>% filter(TrialType == "AI")
data = data %>%
group_by(WorkerId, Plausibility) %>%
mutate(
avrating = mean(Answer.Rating, na.rm=TRUE)
) %>%
ungroup()
data_summ = data %>% group_by(WorkerId, Plausibility) %>%
summarize(
na.pct = mean(na.pct),
n = mean(n),
avrating = mean(avrating),
) %>%
spread(key=Plausibility, value=avrating)
data_summ = merge(data_summ, checksdf, by="WorkerId")
data_summ$diff = data_summ$plausible - data_summ$implausible
## save a summary of individual subjects' performance
write_csv(data_summ,"data_summ_by_worker_new.csv")
write_csv(data_summ,"data_summ_by_worker_new.csv")
# Created on 2020-05-26 by Anna Ivanova
# Based on the code by Rachel Ryskin
# edited on 2021-02-28 by Zawad Chowdhury
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4368386_batch_results_raw.csv',
'../results_raw/Batch_4332828_batch_results_raw.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId'),starts_with('WorkTimeInSeconds'),
starts_with('HITId'), starts_with('AssignmentStatus'),
starts_with('AssignmentId'))
# #get only newly submitted HITs
# data = data %>% filter(AssignmentStatus == "Submitted")
# checksdf = data %>% select(starts_with('WorkerId'))
checksdf = data %>% select(c('WorkerId', 'Answer.English', 'Answer.country',
'Answer.proficiency1', 'Answer.proficiency2',
'WorkTimeInSeconds', 'Answer.answer', 'HITId',
'AssignmentStatus', 'AssignmentId'))
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Input.list,-Answer.country,
-Answer.English,-Answer.answer, -Answer.proficiency1,
-Answer.proficiency2, -WorkTimeInSeconds, -HITId,
-AssignmentStatus, -AssignmentId)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
# exclude bad workers (note: currently done manually)
# data = data %>%
#   filter(!(WorkerId %in% c('AT8S19U5993HR', 'A2R1A479K07ME5')))                   # bad responses
## Summarize ratings data
data$Answer.Rating <- as.numeric(data$Answer.Rating)
## replace plausible-0 with plausible, for easy filtering
data$Input.code <- gsub('plausible-0', 'plausible', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible', data$Input.code)
checksdf$filler.left <- data[data[, "Input.code"]=="filler_filler_2_NO_QUESTION",
"Answer.Rating"]
checksdf$filler.right <- data[data[, "Input.code"]=="filler_filler_1_NO_QUESTION",
"Answer.Rating"]
# separate the Input code into categories
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
# info we don't need
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
# ANALYSES
## Look at data by participant (TODO: fix avg rating for plaus and implaus)
data = data %>%
group_by(WorkerId) %>%
mutate(
na.pct = mean(is.na(Answer.Rating)),
n = length(Answer.Rating),
) %>%
ungroup()
# To look at only AI output
data = data %>% filter(TrialType == "AI")
data = data %>%
group_by(WorkerId, Plausibility) %>%
mutate(
avrating = mean(Answer.Rating, na.rm=TRUE)
) %>%
ungroup()
data_summ = data %>% group_by(WorkerId, Plausibility) %>%
summarize(
na.pct = mean(na.pct),
n = mean(n),
avrating = mean(avrating),
) %>%
spread(key=Plausibility, value=avrating)
data_summ = merge(data_summ, checksdf, by="WorkerId")
data_summ$diff = data_summ$plausible - data_summ$implausible
## save a summary of individual subjects' performance
write_csv(data_summ,"data_summ_by_worker_AIonly_summ.csv")
d = read.csv('data_summ_by_worker_AIonly_summ.csv')
View(d)
d = d %>% filter(Use)
d$WorkerId
cd = d$WorkerId
View(cd)
class(cd)
d[, "WorkerId"]
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results_raw.csv',
'../results_raw/Batch_4368386_batch_results_raw.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId')) %>%
select(-Input.list, -Answer.answer, -Answer.proficiency1,
-Answer.proficiency2)
workers = read.csv("data_summ_by_worker_AIonly_summ.csv")
workers = workers %>% filter(Use)
data = data %>% filter(WorkerId %in% workers$WorkerId)
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId')) %>%
select(-Input.list, -Answer.answer, -Answer.proficiency1,
-Answer.proficiency2)
workers = read.csv("data_summ_by_worker_AIonly_summ.csv")
workers = workers %>% filter(!Use)
View(workers)
# exclude bad workers
# data = data %>%
#   filter(!(WorkerId %in% c('A35LWWZHYTBJES', 'A15A618QS7DD79', 'A1IC1DQ0QQBOOZ',
#                            'A3V2XCDF45VN9X', 'A179LPB3NPSEF8', 'A13ASIJ31D76UN',
#                            'A2717S28QHY09K')))                   # bad responses
workers = read.csv("data_summ_by_worker_AIonly_summ.csv")
workers = workers %>% filter(Use.isna)
workers = workers %>% filter(is.na(Use))
data = data %>% filter(!(WorkerId %in% workers$WorkerId))
data = data %>% gather(key='variable',value="value",
-WorkerId,-Answer.country, -Answer.English,
-Answer.profcheck1, -Answer.profcheck2)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Answer.country, -Answer.English)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
data$Answer.Rating <- as.numeric(data$Answer.Rating)
## replace plausible-0 with plausible0
data$Input.code <- gsub('plausible-0', 'plausible0', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible1', data$Input.code)
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
# Created on 2020-05-26 by Anna Ivanova
# Based on the code by Rachel Ryskin
# edited on 2021-02-28 by Zawad Chowdhury
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results_raw.csv',
'../results_raw/Batch_4368386_batch_results_raw.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId')) %>%
select(-Input.list, -Answer.answer, -Answer.proficiency1,
-Answer.proficiency2)
# exclude bad workers
# data = data %>%
#   filter(!(WorkerId %in% c('A35LWWZHYTBJES', 'A15A618QS7DD79', 'A1IC1DQ0QQBOOZ',
#                            'A3V2XCDF45VN9X', 'A179LPB3NPSEF8', 'A13ASIJ31D76UN',
#                            'A2717S28QHY09K')))                   # bad responses
workers = read.csv("data_summ_by_worker_AIonly_summ.csv")
workers = workers %>% filter(is.na(Use))
data = data %>% filter(!(WorkerId %in% workers$WorkerId))
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Answer.country, -Answer.English)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
## Summarize ratings data
data$Answer.Rating <- as.numeric(data$Answer.Rating)
# Created on 2020-05-26 by Anna Ivanova
# Based on the code by Rachel Ryskin
# edited on 2021-02-28 by Zawad Chowdhury
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results_raw.csv',
'../results_raw/Batch_4368386_batch_results_raw.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId')) %>%
select(-Input.list, -Answer.answer, -Answer.proficiency1,
-Answer.proficiency2)
# exclude bad workers
# data = data %>%
#   filter(!(WorkerId %in% c('A35LWWZHYTBJES', 'A15A618QS7DD79', 'A1IC1DQ0QQBOOZ',
#                            'A3V2XCDF45VN9X', 'A179LPB3NPSEF8', 'A13ASIJ31D76UN',
#                            'A2717S28QHY09K')))                   # bad responses
workers = read.csv("data_summ_by_worker_AIonly_summ.csv")
workers = workers %>% filter(is.na(Use))
data = data %>% filter(!(WorkerId %in% workers$WorkerId))
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Answer.country, -Answer.English)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
View(data)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# Created on 2020-05-26 by Anna Ivanova
# Based on the code by Rachel Ryskin
# edited on 2021-02-28 by Zawad Chowdhury
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results_raw.csv',
'../results_raw/Batch_4368386_batch_results_raw.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId'), starts_with('AssignmentId')) %>%
select(-Input.list, -Answer.answer, -Answer.proficiency1,
-Answer.proficiency2)
# exclude bad workers
# data = data %>%
#   filter(!(WorkerId %in% c('A35LWWZHYTBJES', 'A15A618QS7DD79', 'A1IC1DQ0QQBOOZ',
#                            'A3V2XCDF45VN9X', 'A179LPB3NPSEF8', 'A13ASIJ31D76UN',
#                            'A2717S28QHY09K')))                   # bad responses
workers = read.csv("data_summ_by_worker_AIonly_summ.csv")
workers = workers %>% filter(is.na(Use))
data = data %>% filter(!(WorkerId %in% workers$WorkerId))
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Answer.country, -Answer.English)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
# spread
data = data %>% spread(key = Type, value = value)
# Created on 2020-05-26 by Anna Ivanova
# Based on the code by Rachel Ryskin
# edited on 2021-02-28 by Zawad Chowdhury
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results_raw.csv',
'../results_raw/Batch_4368386_batch_results_raw.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId'), starts_with('AssignmentId')) %>%
select(-Input.list, -Answer.answer, -Answer.proficiency1,
-Answer.proficiency2)
# exclude bad workers
# data = data %>%
#   filter(!(WorkerId %in% c('A35LWWZHYTBJES', 'A15A618QS7DD79', 'A1IC1DQ0QQBOOZ',
#                            'A3V2XCDF45VN9X', 'A179LPB3NPSEF8', 'A13ASIJ31D76UN',
#                            'A2717S28QHY09K')))                   # bad responses
workers = read.csv("data_summ_by_worker_AIonly_summ.csv")
workers = workers %>% filter(is.na(Use))
data = data %>% filter(!(WorkerId %in% workers$WorkerId))
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Answer.country, -Answer.English, -AssignmentId)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
data$Answer.Rating <- as.numeric(data$Answer.Rating)
## replace plausible-0 with plausible0
data$Input.code <- gsub('plausible-0', 'plausible0', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible1', data$Input.code)
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
## SAVE A LONGFORM VERSION OF YOUR DATA
write_csv(data,"longform_data.csv")
summ_by_item = data %>%
group_by(Voice, Plausibility, Item) %>%
summarize(
n = length(Answer.Rating),
mean = mean(Answer.Rating)
)
View(summ_by_item)
summ_by_item = data %>%
group_by(Voice, Plausibility, Item) %>%
summarize(
n = length(Answer.Rating),
mean = mean(Answer.Rating, na.rm = TRUE)
)
write.csv(summ_by_item, "data_by_item")
write.csv(summ_by_item, "data_by_item.csv")
