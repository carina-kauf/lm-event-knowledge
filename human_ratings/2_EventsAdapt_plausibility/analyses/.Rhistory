## replace plausible-0 with plausible, for easy filtering
data$Input.code <- gsub('plausible-0', 'plausible', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible', data$Input.code)
checksdf$filler.left <- data[data[, "Input.code"]=="filler_filler_2_NO_QUESTION",
"Answer.Rating"]
checksdf$filler.right <- data[data[, "Input.code"]=="filler_filler_1_NO_QUESTION",
"Answer.Rating"]
# separate the Input code into categories
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
# info we don't need
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
# ANALYSES
## Look at data by participant (TODO: fix avg rating for plaus and implaus)
data = data %>%
group_by(WorkerId) %>%
mutate(
na.pct = mean(is.na(Answer.Rating)),
n = length(Answer.Rating),
) %>%
ungroup()
# To look at only AI output
data = data %>% filter(TrialType == "AI")
data = data %>%
group_by(WorkerId, Plausibility) %>%
mutate(
avrating = mean(Answer.Rating, na.rm=TRUE)
) %>%
ungroup()
data_summ = data %>% group_by(WorkerId, Plausibility) %>%
summarize(
na.pct = mean(na.pct),
n = mean(n),
avrating = mean(avrating),
) %>%
spread(key=Plausibility, value=avrating)
data_summ = merge(data_summ, checksdf, by="WorkerId")
data_summ$diff = data_summ$plausible - data_summ$implausible
## get profcheck from before
f = c('data_summ_by_worker_AIonly_oldchecks.csv')
data_old <- lapply(f, read.csv)
data_old = do.call("rbind", data_old)
data_old = data_old %>% select(c('WorkerId', 'HITId', 'profcheck'))
data_summ <- merge(data_summ, data_old, by=c("WorkerId", "HITId"), all=TRUE)
write_csv(data_summ,"data_summ_by_worker_AIonly_summ.csv")
# Created on 2020-05-26 by Anna Ivanova
# Based on the code by Rachel Ryskin
# edited on 2021-02-28 by Zawad Chowdhury
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4368386_batch_results_raw.csv',
'../results_raw/Batch_4332828_batch_results_raw.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId'),starts_with('WorkTimeInSeconds'),
starts_with('HITId'), starts_with('AssignmentStatus'),
starts_with('AssignmentId'))
# #get only newly submitted HITs
# data = data %>% filter(AssignmentStatus == "Submitted")
# checksdf = data %>% select(starts_with('WorkerId'))
checksdf = data %>% select(c('WorkerId', 'Answer.English', 'Answer.country',
'Answer.proficiency1', 'Answer.proficiency2',
'WorkTimeInSeconds', 'Answer.answer', 'HITId',
'AssignmentStatus', 'AssignmentId'))
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Input.list,-Answer.country,
-Answer.English,-Answer.answer, -Answer.proficiency1,
-Answer.proficiency2, -WorkTimeInSeconds, -HITId,
-AssignmentStatus, -AssignmentId)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
# exclude bad workers (note: currently done manually)
# data = data %>%
#   filter(!(WorkerId %in% c('AT8S19U5993HR', 'A2R1A479K07ME5')))                   # bad responses
## Summarize ratings data
data$Answer.Rating <- as.numeric(data$Answer.Rating)
## replace plausible-0 with plausible, for easy filtering
data$Input.code <- gsub('plausible-0', 'plausible', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible', data$Input.code)
checksdf$filler.left <- data[data[, "Input.code"]=="filler_filler_2_NO_QUESTION",
"Answer.Rating"]
checksdf$filler.right <- data[data[, "Input.code"]=="filler_filler_1_NO_QUESTION",
"Answer.Rating"]
# separate the Input code into categories
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
# info we don't need
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
# ANALYSES
## Look at data by participant (TODO: fix avg rating for plaus and implaus)
data = data %>%
group_by(WorkerId) %>%
mutate(
na.pct = mean(is.na(Answer.Rating)),
n = length(Answer.Rating),
) %>%
ungroup()
# To look at only AI output
data = data %>% filter(TrialType == "AI")
data = data %>%
group_by(WorkerId, Plausibility) %>%
mutate(
avrating = mean(Answer.Rating, na.rm=TRUE)
) %>%
ungroup()
data_summ = data %>% group_by(WorkerId, Plausibility) %>%
summarize(
na.pct = mean(na.pct),
n = mean(n),
avrating = mean(avrating),
) %>%
spread(key=Plausibility, value=avrating)
data_summ = merge(data_summ, checksdf, by="WorkerId")
data_summ$diff = data_summ$plausible - data_summ$implausible
write_csv(data_summ,"data_summ_by_worker_AIonly_summ_withoutmerge.csv")
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4430335_batch_results_raw.csv',)
# READ DATA
filenames=c('../results_raw/Batch_4430335_batch_results_raw.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId'),starts_with('WorkTimeInSeconds'),
starts_with('HITId'), starts_with('AssignmentStatus'),
starts_with('AssignmentId'))
checksdf = data %>% select(c('WorkerId', 'Answer.English', 'Answer.country',
'Answer.proficiency1', 'Answer.proficiency2',
'WorkTimeInSeconds', 'Answer.answer', 'HITId',
'AssignmentStatus', 'AssignmentId'))
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Input.list,-Answer.country,
-Answer.English,-Answer.answer, -Answer.proficiency1,
-Answer.proficiency2, -WorkTimeInSeconds, -HITId,
-AssignmentStatus, -AssignmentId)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
## Summarize ratings data
data$Answer.Rating <- as.numeric(data$Answer.Rating)
## replace plausible-0 with plausible, for easy filtering
data$Input.code <- gsub('plausible-0', 'plausible', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible', data$Input.code)
checksdf$filler.left <- data[data[, "Input.code"]=="filler_filler_2_NO_QUESTION",
"Answer.Rating"]
checksdf$filler.right <- data[data[, "Input.code"]=="filler_filler_1_NO_QUESTION",
"Answer.Rating"]
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
data = data %>%
group_by(WorkerId) %>%
mutate(
na.pct = mean(is.na(Answer.Rating)),
n = length(Answer.Rating),
) %>%
ungroup()
# To look at only AI output
data = data %>% filter(TrialType == "AI")
data = data %>%
group_by(WorkerId, Plausibility) %>%
mutate(
avrating = mean(Answer.Rating, na.rm=TRUE)
) %>%
ungroup()
data_summ = data %>% group_by(WorkerId, Plausibility) %>%
summarize(
na.pct = mean(na.pct),
n = mean(n),
avrating = mean(avrating),
) %>%
spread(key=Plausibility, value=avrating)
data_summ = merge(data_summ, checksdf, by="WorkerId")
data_summ$diff = data_summ$plausible - data_summ$implausible
write_csv(data_summ,"data_summ_by_worker_finalbatch_summ.csv")
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results_raw.csv',
'../results_raw/Batch_4368386_batch_results_raw.csv',
'../results_raw/Batch_4430335_batch_results_raw.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId'), starts_with('AssignmentId')) %>%
select(-Input.list, -Answer.answer, -Answer.proficiency1,
-Answer.proficiency2)
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
library(tidyverse)
install.packages("broom")
library(tidyverse)
remove.packages("tidyverse")
install.packages("tidyverse")
library(tidyverse)
rm(list=ls())
library(tidyverse)
install.packages("R6")
library(tidyverse)
library(stringr)
library(tidyverse)
install.packages("generics")
library(tidyverse)
install.packages("glue")
library(tidyverse)
install.packages("lifecycle")
install.packages("lifecycle")
library(tidyverse)
install.packages("pillar")
library(tidyverse)
rm(list=ls())
library(tidyverse)
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results_raw.csv',
'../results_raw/Batch_4368386_batch_results_raw.csv',
'../results_raw/Batch_4430335_batch_results_raw.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId'), starts_with('AssignmentId')) %>%
select(-Input.list, -Answer.answer, -Answer.proficiency1,
-Answer.proficiency2)
view(data)
# exclude bad workers
# data = data %>%
#   filter(!(WorkerId %in% c('A35LWWZHYTBJES', 'A15A618QS7DD79', 'A1IC1DQ0QQBOOZ',
#                            'A3V2XCDF45VN9X', 'A179LPB3NPSEF8', 'A13ASIJ31D76UN',
#                            'A2717S28QHY09K')))                   # bad responses
workers = read.csv("data_summ_by_worker_ALL.csv")
view(workers)
workers = workers %>% filter(good_data == "yes")
view(workers)
# exclude bad workers
# data = data %>%
#   filter(!(WorkerId %in% c('A35LWWZHYTBJES', 'A15A618QS7DD79', 'A1IC1DQ0QQBOOZ',
#                            'A3V2XCDF45VN9X', 'A179LPB3NPSEF8', 'A13ASIJ31D76UN',
#                            'A2717S28QHY09K')))                   # bad responses
bad_workers = read.csv("data_summ_by_worker_ALL.csv")
bad_workers = workers %>% filter(good_data == "no")
view(bad_workers)
# exclude bad workers
# data = data %>%
#   filter(!(WorkerId %in% c('A35LWWZHYTBJES', 'A15A618QS7DD79', 'A1IC1DQ0QQBOOZ',
#                            'A3V2XCDF45VN9X', 'A179LPB3NPSEF8', 'A13ASIJ31D76UN',
#                            'A2717S28QHY09K')))                   # bad responses
bad_workers = read.csv("data_summ_by_worker_ALL.csv")
view(bad_workers)
bad_workers = bad_workers %>% filter(good_data == "no")
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results_raw.csv',
'../results_raw/Batch_4368386_batch_results_raw.csv',
'../results_raw/Batch_4430335_batch_results_raw.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId'), starts_with('AssignmentId')) %>%
select(-Input.list, -Answer.answer, -Answer.proficiency1,
-Answer.proficiency2)
# exclude bad workers
# data = data %>%
#   filter(!(WorkerId %in% c('A35LWWZHYTBJES', 'A15A618QS7DD79', 'A1IC1DQ0QQBOOZ',
#                            'A3V2XCDF45VN9X', 'A179LPB3NPSEF8', 'A13ASIJ31D76UN',
#                            'A2717S28QHY09K')))                   # bad responses
bad_workers = read.csv("data_summ_by_worker_ALL.csv")
bad_workers = bad_workers %>% filter(good_data == "no")
view(bad_workers)
data = data %>% filter(!(WorkerId %in% workers$WorkerId))
data = data %>% filter(!(WorkerId %in% bad_workers$WorkerId))
view(data)
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId,-Answer.country, -Answer.English, -AssignmentId)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
## Summarize ratings data
data$Answer.Rating <- as.numeric(data$Answer.Rating)
## replace plausible-0 with plausible0
data$Input.code <- gsub('plausible-0', 'plausible0', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible1', data$Input.code)
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
# info we don't need
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
view(data)
data$xx2 = NULL
view(data)
# Created on 2020-05-26 by Anna Ivanova
# Based on the code by Rachel Ryskin
# edited on 2021-02-28 by Zawad Chowdhury
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results_raw.csv',
'../results_raw/Batch_4368386_batch_results_raw.csv',
'../results_raw/Batch_4430335_batch_results_raw.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId'), starts_with('AssignmentId')) %>%
select(-Input.list, -Answer.answer, -Answer.proficiency1,
-Answer.proficiency2, -Answer.English, -Answer.country)
# exclude bad workers
# data = data %>%
#   filter(!(WorkerId %in% c('A35LWWZHYTBJES', 'A15A618QS7DD79', 'A1IC1DQ0QQBOOZ',
#                            'A3V2XCDF45VN9X', 'A179LPB3NPSEF8', 'A13ASIJ31D76UN',
#                            'A2717S28QHY09K')))                   # bad responses
bad_workers = read.csv("data_summ_by_worker_ALL.csv")
bad_workers = bad_workers %>% filter(good_data == "no")
data = data %>% filter(!(WorkerId %in% bad_workers$WorkerId))
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId, -AssignmentId)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
## Summarize ratings data
data$Answer.Rating <- as.numeric(data$Answer.Rating)
## replace plausible-0 with plausible0
data$Input.code <- gsub('plausible-0', 'plausible0', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible1', data$Input.code)
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
# info we don't need
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
view(data)
## SAVE A LONGFORM VERSION OF YOUR DATA
write_csv(data,"longform_data.csv")
summ_by_item = data %>%
group_by(Voice, Plausibility, Item) %>%
summarize(
n = length(Answer.Rating),
mean = mean(Answer.Rating, na.rm = TRUE)
)
write.csv(summ_by_item, "data_by_item.csv")
## Look at data by participant (TODO: fix avg rating for plaus and implaus)
data = data %>%
group_by(WorkerId) %>%
mutate(
na.pct = mean(is.na(Answer.Rating)),
n = length(Answer.Rating)) %>%
ungroup()
z_score = function(xs) {
(xs - mean(xs)) / sd(xs)
}
#Remove filler checks
data$Item = as.numeric(data$Item)
data.good = data %>%
filter(TrialType != "filler" &
n <= num.trials) %>%
filter(!is.na(Answer.Rating)) %>%
select(-na.pct, -n)
write_csv(data.good,"good_data.csv")
data.good.summary = data.good %>%
group_by(Item, Plausibility, Voice) %>%
summarize(
m = mean(Answer.Rating),
stdev= sd(Answer.Rating),
#    se = stdev/sqrt(n()),
#    upper= m+se*1.96,
#    lower=m-se*1.96
)
## save a summary of individual subjects' performance
# data.good.summary = data.good.summary[,c(2,1,3,4, 5)]
write_csv(data.good.summary[order(data.good.summary$Item),],
"EventsAdapt_data_summ.csv")
# Created on 2020-05-26 by Anna Ivanova
# Based on the code by Rachel Ryskin
# edited on 2021-02-28 by Zawad Chowdhury
rm(list=ls())
library(tidyverse)
library(stringr)
library(stringi)
# READ DATA
filenames=c('../results_raw/Batch_4332828_batch_results_raw.csv',
'../results_raw/Batch_4368386_batch_results_raw.csv',
'../results_raw/Batch_4430335_batch_results_raw.csv')
data <- lapply(filenames, read.csv)
data = do.call("rbind", data)
num.trials = 54  # maximum number of trials per participant
# only keep WorkerId and cols that Start with Answer or Input
data = data %>% select(starts_with('Input'),starts_with('Answer'),
starts_with('WorkerId'), starts_with('AssignmentId')) %>%
select(-Input.list, -Answer.answer, -Answer.proficiency1,
-Answer.proficiency2, -Answer.English, -Answer.country)
# exclude bad workers
# data = data %>%
#   filter(!(WorkerId %in% c('A35LWWZHYTBJES', 'A15A618QS7DD79', 'A1IC1DQ0QQBOOZ',
#                            'A3V2XCDF45VN9X', 'A179LPB3NPSEF8', 'A13ASIJ31D76UN',
#                            'A2717S28QHY09K')))                   # bad responses
bad_workers = read.csv("data_summ_by_worker_ALL.csv")
bad_workers = bad_workers %>% filter(good_data == "no")
data = data %>% filter(!(WorkerId %in% bad_workers$WorkerId))
# gather (specify the list of columns you need)
data = data %>% gather(key='variable',value="value",
-WorkerId, -AssignmentId)
# separate
data = data %>% separate(variable, into=c('Type','TrialNum'),sep='__',convert=TRUE)
# spread
data = data %>% spread(key = Type, value = value)
## Summarize ratings data
data$Answer.Rating <- as.numeric(data$Answer.Rating)
## replace plausible-0 with plausible0
data$Input.code <- gsub('plausible-0', 'plausible0', data$Input.code)
data$Input.code <- gsub('plausible-1', 'plausible1', data$Input.code)
data = data %>%
separate(Input.code,into=c('TrialType','cond','Item','xx1','xx2'),sep='_') %>%
separate(cond, into=c('Voice', 'Plausibility', 'xx3'), sep='-')
# info we don't need
data$xx3 = NULL
data$xx1 = NULL
data$xx2 = NULL
# ANALYSES
## Look at data by participant (TODO: fix avg rating for plaus and implaus)
data = data %>%
group_by(WorkerId) %>%
mutate(
na.pct = mean(is.na(Answer.Rating)),
n = length(Answer.Rating)) %>%
ungroup()
#
# data_summ = data %>%
#   group_by(WorkerId) %>%
#   summarize(
#     na.pct = mean(is.na(Answer.Rating)),
#     n = length(Answer.Rating))
#
# data_byplausibility = data %>%
#   group_by(WorkerId, Plausibility) %>%
#   summarise_at(c("Answer.Rating"), funs(mean(., na.rm=TRUE)))
## save a summary of individual subjects' performance
# write_csv(data_summ,"data_summ_by_worker.csv")
z_score = function(xs) {
(xs - mean(xs)) / sd(xs)
}
#Remove filler checks
data$Item = as.numeric(data$Item)
data.good = data %>%
filter(TrialType != "filler" &
n <= num.trials) %>%
filter(!is.na(Answer.Rating)) %>%
select(-na.pct, -n)
write_csv(data.good,"longform_data.csv")
data.good.summary = data.good %>%
group_by(Item, Plausibility, Voice) %>%
summarize(
n = length(Answer.Rating),
m = mean(Answer.Rating),
stdev= sd(Answer.Rating),
se = stdev/sqrt(n()),
upper= m+se*1.96,
lower=m-se*1.96
)
## save a summary of individual subjects' performance
# data.good.summary = data.good.summary[,c(2,1,3,4, 5)]
write_csv(data.good.summary[order(data.good.summary$Item),],
"EventsAdapt_data_summ.csv")
