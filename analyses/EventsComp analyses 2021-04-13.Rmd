---
title: "EventsComp analyses 2020-09-14"
author: "Anna Ivanova"
date: "9/14/2020"
output: html_document
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls()) 
library(ggplot2)
library(dplyr)
#library(reshape)

# custom function to read a datatable
read_data <- function(directory, filename) {
  d = read.delim(paste(directory, filename, sep='/'), 
                 header=FALSE, sep='\t')
  
  if (ncol(d)==4) {
    d = d %>% rename(SentenceNum=V1, Sentence=V2, Plausibility=V3, Score=V4) %>%
      mutate(ItemNum = SentenceNum %/% 2)
  } else if (ncol(d)==3) {
    d = d  %>%
      rename(SentenceNum=V1, Sentence=V2, Score=V3) %>%
      mutate(ItemNum = SentenceNum %/% 2) %>%
      mutate(Plausibility = ifelse(SentenceNum%%2==0, 'Plausible', 'Implausible')) 
  } else {
    stop('unexpected number of columns in file')
  }

  d = d %>% 
    mutate(Metric = substr(filename,1,nchar(filename)-4))
  return(d)
}
```

# DTFit
## Load data
```{r read data, echo=FALSE}
files = list.files(path='Dataset_DTFit', pattern="*.txt")
dat = do.call(rbind, lapply(files, function(x) read_data('Dataset_DTFit', x)))

# remove file with inconsistent formatting
# and normalize scores
dat = dat %>% 
  filter(Metric!='fast_vector_sum_DTFit') %>%
  #group_by(Metric) %>% mutate(NormScore =scale(Score, center=FALSE, scale=max(Score)))
  group_by(Metric) %>% mutate(NormScore =scale(Score))
```


## Plot the scores

```{r plot scores, echo=FALSE}
ggplot(data=dat)+
    # stat_summary(mapping=aes(x=Metric, y=Score, fill=Typicality),
    #            geom='bar', fun.y='mean', position='dodge',
    #            color='black', width=0.5)+
    geom_point(mapping = aes(x=Metric, y=NormScore, fill=Typicality),
             shape=21, size=0.75, color='black',
             position=position_jitterdodge(jitter.width=0.15, jitter.height=0, dodge.width=.5),
             show.legend = TRUE)+
  geom_hline(yintercept=0, linetype='dotted')+theme_classic()+coord_flip()
```

## Difference / Binary Choice

```{r pressure, echo=FALSE}
dat.binchoice = dat %>% group_by(SentenceNum, Metric) %>%
  summarise(ScoreDiff = Score[Typicality=="T"]-Score[Typicality=="AT"]) %>%
  mutate(Accuracy = ifelse(ScoreDiff>0, 1, 0))
```

```{r}
ggplot(data=dat.binchoice)+
  stat_summary(mapping=aes(x=Metric, y=Accuracy),
               geom='bar', fun.y='mean',
               color='black', width=0.5)+
  geom_hline(yintercept=0.5, linetype='dashed')+
  geom_hline(yintercept=0, linetype='dotted')+theme_classic()+
  labs(x=NULL, y='Accuracy')+
  theme(axis.text.x=element_text(size=12), 
        axis.title.y=element_text(size=14))+
  coord_cartesian(ylim=c(0,1))+
  coord_flip()
```

# EventsRev
## Load data
```{r read data, echo=FALSE}
dirname = 'model_data/EventsRev/'
files = list.files(path=dirname, pattern="*.txt")
dat = do.call(rbind, lapply(files, function(x) read_data(dirname, x)))

dat$Score[grep("ANN", dat$Metric)] = log(dat$Score[grep("ANN", dat$Metric)])

dat = dat %>% 
#  filter(Metric!='fast_vector_sum_ev') %>%
  #group_by(Metric) %>% mutate(NormScore =scale(Score, center=FALSE, scale=max(Score)))
  #mutate(Score = ifelse(starts_with(as.character(Metric), 'ANN'), log(Score), Score)) %>%
  group_by(Metric) %>% mutate(NormScore =scale(Score))
```

## Plot the scores

```{r plot scores, echo=FALSE}
ggplot(data=dat)+
    geom_violin(mapping = aes(x=Metric, y=NormScore, fill=Plausibility), 
                scale='width', width=0.6, alpha=0.5, position=position_dodge(width=0.6))+
    geom_point(mapping = aes(x=Metric, y=NormScore, fill=Plausibility),
             shape=21, size=0.75, color='black',
             position=position_jitterdodge(jitter.width=0.15, jitter.height=0, dodge.width=.6),
             show.legend = TRUE)+
  labs(x='Model')+
  geom_hline(yintercept=0, linetype='dotted')+theme_classic()+coord_flip()
ggsave('plots/EventsRev/binary_distribution.png', width=16, height=12, units='cm')
```

## Difference / Binary Choice

```{r, echo=FALSE}
dat.binchoice = dat %>% 
  group_by(ItemNum, Metric) %>%
  summarise(ScoreDiff = Score[Plausibility=="Plausible"]-Score[Plausibility=="Implausible"]) %>%
  mutate(Accuracy = ifelse(ScoreDiff>=0, 1, 0))
```

```{r}
#get confidence interval
b = binom.test(20, 40, p=0.5, alternative='t')
ci= b$conf.int

#plot
ggplot(data=dat.binchoice)+
  geom_rect(xmin=-Inf, xmax=Inf, ymin=ci[1], ymax=ci[2], fill='gray90', alpha=0.04)+
  stat_summary(mapping=aes(x=Metric, y=Accuracy),
               geom='bar', fun.y='mean',
               color='black', width=0.5)+
  geom_hline(yintercept=0.5, linetype='dashed')+
  geom_hline(yintercept=0, linetype='dotted')+theme_classic()+
  labs(x='Model', y='Accuracy')+
  theme(axis.text.x=element_text(size=12), 
        axis.title.y=element_text(size=14))+
  coord_cartesian(ylim=c(0,1))+
  coord_flip()
ggsave('plots/EventsRev/binary_choice.png', width=16, height=12, units='cm')
```

## Item variation

```{r}
dat.wide = dat %>% 
  dplyr::select(SentenceNum, Metric, Score) %>%
  spread(Metric, Score) %>%
  rename('human_ratings' = '_human_ratings',
         'GPT2_XL' = 'ANN_gpt2-xl.all') %>%
  mutate(ItemNum = as.character(SentenceNum%/%2))

dat.wide.subset = dat.wide %>% filter(ItemNum %in% c(1,2,3,4,5))

ggplot()+
  geom_point(data=dat.wide, mapping=aes(x=GPT2_XL, y=human_ratings), color='gray', size=2)+
  geom_point(data=dat.wide.subset, mapping=aes(x=GPT2_XL, y=human_ratings, fill=ItemNum),
             size=3)+theme_classic()+
ggsave('plots/EventsRev/scatter_GPT2xl_humans.png', width=16, height=12, units='cm')
```


# SentAdapt
## Load data
```{r read data, echo=FALSE}
files = list.files(path='Dataset_ev2_new', pattern="*.txt")
dat = do.call(rbind, lapply(files, function(x) read_data('Dataset_ev2_new', x)))

# remove file with inconsistent formatting
# and normalize scores
dat = dat %>% 
  group_by(Metric) %>% mutate(NormScore =scale(Score))
```

## Plot the scores

```{r plot scores, echo=FALSE}
ggplot(data=dat)+
    geom_point(mapping = aes(x=Metric, y=NormScore, fill=Typicality),
             shape=21, size=0.75, color='black',
             position=position_jitterdodge(jitter.width=0.15, jitter.height=0, dodge.width=.5),
             show.legend = TRUE)+
    # stat_summary(mapping=aes(x=Metric, y=Score, fill=Typicality),
    #            geom='bar', fun.y='mean', position='dodge',
    #            color='black', width=0.5)+
  geom_hline(yintercept=0, linetype='dotted')+theme_classic()+coord_flip()
```

## Difference / Binary Choice

```{r pressure, echo=FALSE}
# exclude control sentences for now
dat.binchoice = dat %>% 
  filter(SentenceNum<549) %>%
  group_by(SentenceNum, Metric) %>%
  summarise(ScoreDiff = Score[Typicality=="Plausible"]-Score[Typicality=="Implausible"]) %>%
  mutate(Accuracy = ifelse(ScoreDiff>0, 1, 0))
```

```{r}
ggplot(data=dat.binchoice %>% filter())+
  stat_summary(mapping=aes(x=Metric, y=Accuracy),
               geom='bar', fun.y='mean',
               color='black', width=0.5)+
  geom_hline(yintercept=0.5, linetype='dashed')+
  geom_hline(yintercept=0, linetype='dotted')+theme_classic()+
  labs(x=NULL, y='Accuracy')+
  theme(axis.text.x=element_text(size=12), 
        axis.title.y=element_text(size=14))+
  coord_cartesian(ylim=c(0,1))+
  coord_flip()
```