---
title: "preprocess_dataframes"
output: html_document
---

Returns clean dataframes (after excluding sentences that are mismatched between models/humans) for:
- sentence set
- human judgments
- model + human.mean score

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
rm(list=ls()) 
library(dplyr)
library(tidyr)
library(stringr)

source('dataloader_utils.R') #includes read_data function
savedir <- paste("clean_data")
if (!dir.exists(savedir)) {dir.create(savedir)}
```

```{r}
experiment = 'EventsAdapt' # can be 'EventsAdapt' or 'EventsRev'
normalization <- "min-max" #can be "min-max", "zscore"
```

```{r}
if (grepl("min-max", normalization) == TRUE){
  normalization <- function(x) {
    return(min_max(x)) }
} else {
  normalization <- function(x) {
    return(scale_this(x)) }
}
```

# Read sentence freq data

```{r}
dirname = '../word_frequency_info'
sentence_file = paste(dirname, paste(experiment, 'freqs.csv', sep='_'), sep='/')

# read in & normalize predictors
dat.sentence = read.csv(sentence_file) %>%
  mutate(agent_freq_norm = (agent_freq - mean(agent_freq))/sd(agent_freq),
         patient_freq_norm = (patient_freq - mean(patient_freq))/sd(patient_freq),
         verb_freq_norm = (verb_freq - mean(verb_freq))/sd(verb_freq),
         sentence_freq_norm = (sentence_freq - mean(sentence_freq))/sd(sentence_freq))
if (experiment=='EventsRev') {
  dat.sentence$TrialType = 'AAN'         
  dat.sentence$Voice = 'active'
}

dat.sentence$Plausibility = recode(dat.sentence$Plausibility, 
                             implausible='Implausible', plausible='Plausible',
                             implaus="Implausible", plaus="Plausible") 
dat.sentence$Experiment = experiment
```

```{r}
# randomly assign plausibility values to AAR, use even/odd heuristic for the rest
if (experiment=='EventsAdapt'){
  dat.sentence$Index = c(1:nrow(dat.sentence))
  dat.sentence = dat.sentence %>%
    mutate(Plausibility = ifelse((Index%%2==0), 'Implausible', 'Plausible')) %>%
    select(-Index)
}
```

## Add synonym info
```{r}
# Items after the new ItemNum 278 do not have synonyms
if (experiment=='EventsAdapt'){
  dat.sentence = dat.sentence %>%
      mutate(SynonymPair = ifelse(ItemNum>278, NA, (ItemNum+1)%/%2)) %>% 
      mutate(NumSyn = ifelse(ItemNum>278, NA, paste('Version', (ItemNum+1)%%2+1, sep="")))
}
```

# Read human data

```{r}
# READ
dirname = '../human_ratings'
expt_index = ifelse(experiment=='EventsRev', '1', '2')
ratings_file = paste(dirname, paste(expt_index, experiment, 'plausibility', sep='_'), 
                     'analyses', 'longform_data.csv', sep='/')

dat.human = read.csv(ratings_file) %>% rename(Score=Answer.Rating) %>%
  rename(Sentence=Input.trial) %>%
  rename(ItemNum=Item)

if (experiment=='EventsRev') {
  dat.human = dat.human %>%
    select(WorkerId, Score, Plausibility, ItemNum, Sentence) %>%
    filter(ItemNum<41)    # exclude attention checks
  dat.human$TrialType = 'AAN'           
  dat.human$Voice = 'active'
} else {
    dat.human = dat.human %>%
      select(WorkerId, Score, Plausibility, ItemNum, Sentence, TrialType, Voice)
}

# CLEAN
dat.human$Plausibility = recode(dat.human$Plausibility, 
                             implausible='Implausible', plausible='Plausible',
                             implaus="Implausible", plaus="Plausible",
                             plausible0='Implausible', plausible1='Plausible') 

dat.human$TrialType = factor(dat.human$TrialType, levels=c('AI', 'AAN', 'AAR'))
```

## Get the human mean score (to compare w models)

```{r pressure, echo=FALSE}
dat.human.mean = dat.human %>% 
  group_by(ItemNum, Sentence, Plausibility, TrialType, Voice) %>%
  summarize(MeanScore = mean(Score, na.rm=TRUE)) %>%
  ungroup() 
dat.human.mean$ItemNum = as.factor(dat.human.mean$ItemNum)

#scale scores
dat.human.mean = dat.human.mean %>%
  mutate(NormScore = normalization(MeanScore))
```

# Read model scores
```{r read data, echo=FALSE}
dirname = paste('..', 'model_scores', experiment, sep='/')

message(paste('Loading', experiment, 'model data ...'))
filenames = list.files(path=dirname, pattern='*.txt')
dat.models = do.call(rbind, lapply(filenames, function(x) read_data(dirname, x)))
```

## Merge with sentence info

```{r read data, echo=FALSE}
dat.models = dat.models %>% select(-ItemNum, -Plausibility, -SentenceNum)
if (any(sapply(dat.models$Sentence, function(x) {!(x %in% dat.sentence$Sentence)}))) {
  shared_sentences = intersect(unique(dat.models$Sentence), unique(dat.sentence$Sentence))
  excluded = dat.models %>% filter(!(Sentence %in% shared_sentences)) %>%
    select(Sentence) %>% distinct()
  warning(paste('Not all sentences are in the sentence info file. Excluding:',
                excluded, sep='\n'))
  dat.models = dat.models %>%
    filter(Sentence %in% shared_sentences)
}
dat = merge(dat.models, dat.sentence, by=c("Sentence"))

# check which sentences don't have a plausibility pair
sentence_pairnum = dat %>%
  group_by(ItemNum, TrialType, Voice, Metric) %>%
  summarize(NumSentences = length(ItemNum)) %>%
  ungroup()
single_sentences = sentence_pairnum %>%
  filter(NumSentences==1) %>% 
  select(ItemNum) %>%
  distinct()

# filter them out
dat = dat %>%
  filter(!(ItemNum %in% single_sentences$ItemNum))
```


## Add human data
```{r}
# only include sentences present in model data
dat.human.mean = dat.human.mean %>%
  filter(ItemNum %in% unique(dat$ItemNum)) %>%
  select(Sentence, MeanScore, NormScore) %>%
  rename(Score=MeanScore)
dat.human.mean = merge(dat.human.mean, dat.sentence, by=c("Sentence"))

# combine
dat.human.mean$Metric = "human"
dat = rbind(dat, dat.human.mean)
```


# Plausibility

We need to define for which models a higher score for plausible sentences is desirable:

1. HIGHER = MORE PLAUSIBLE
    * ANNs >> metric is probability
    * PPMI >> higher PMI indicates a plausible sentence
    * Vector similarity
    * TFit similarity (sum of vector similarities to prototype vector)
    * SDM (sum of some vector similarities)
2. LOWER = MORE PLAUSIBLE
    * Surprisal

```{r pressure, echo=FALSE}

lower_better = c("surprisal")
lower_better_pat <- paste(lower_better, collapse = '|')

# Add FinalNormScore for NormScores plotting in the same direction for all metrics (i.e., Plausible is more positive)
dat = dat %>%
  mutate(LowerBetter = ifelse(grepl(lower_better_pat, Metric),TRUE,FALSE)) %>%
  mutate(FinalNormScore = ifelse(LowerBetter==TRUE, -NormScore+1, NormScore))
```

# Sentence exclusion

## Assimilate sentence sets between models & humans
```{r}
# make sure sentences are the same for humans and models
shared_sentences = intersect(dat.human.mean$Sentence, dat.models$Sentence)
if (any(sapply(dat$Sentence, function(x) {!(x %in% shared_sentences)}))) {
  excluded = dat.models %>% filter(!(Sentence %in% shared_sentences)) %>%
    select(Sentence) %>% distinct()
  warning(paste('Sentence mismatch between models and humans. Excluding:',
                excluded, sep='\n'))
  dat = dat %>% filter(Sentence %in% shared_sentences)
}

# keep only sentences with pairs
dat = dat %>%
  group_by(ItemNum, Metric, Voice) %>%
  filter(length(ItemNum)==2) %>%
  ungroup()

# reassign item numbers based on human data (for consistency)
sentnums_humans = dat.human.mean %>%
  select(ItemNum, Sentence)
dat = merge(sentnums_humans, dat %>% select(-ItemNum))

# make sure that item numbers are the same everywhere
item_sent_combos = dat %>%
  group_by(Sentence) %>%
  mutate(Count=length(unique(ItemNum)))
if (any(sapply(item_sent_combos$Count, function(x) {x!=1}))) {
  print(item_sent_combos %>% filter(Count!=1))
  stop('Item number mismatch across metrics')
}
```



# KEYWORD EXCLUSION

## Define keywords
```{r}
# NOTE: not all sentences are SVO; sometimes it's the agent and the recipient who are switched
if (experiment=='EventsAdapt'){
  exclusion_keywords = c('designer',
                       'decorator',
                       #
                       'pants',
                       'trousers',
                       #
                       'owner',        # REMAINED
                       'proprietor',
                       #
                       'spectators',
                       'audience',        # REMAINED
                       #
                       'illusionist',
                       'magician',        # REMAINED
                       #
                       'ancestors',
                       'serf',
                       #
                       'dictator',
                       'townspeople',        # REMAINED
                       #
                       'runner',
                       'jogger',
                       #
                       'officer',
                       'deputy',
                       #
                       'hunter',        # REMAINED
                       'perpetrator',
                       #
                       'closed', # doesn't come with a synonym
                       'cushion', # doesn't come with a synonym
                       'pullover',  # doesn't come with a synonym
                       'soda', # doesn't come with a synonym
                       'woodworker', # doesn't come with a synonym
                       'target', # doesn't come with a synonym
                       'pine',  # doesn't come with a synonym
                       'smuggler',  # doesn't come with a synonym
                       'fired',  # doesn't come with a synonym
                       'beverage', #7 doesn't come with a synonym
                       'box-office', #282 no synonym
                       'counselor', #293 no synonym
                       'laundress', #306 no synonym
                       'twins', #328 no synonym
                       'fashionista' #379 no synonym
                       )
} else {
  exclusion_keywords = c('sportsstar', #922 no synonym
                       'applauding' #927 no synonym
                       )
}
```

## exclude from dataset
```{r}
#exclude sentences based on those that are not shared between models and humans in the dataset
message(paste('num sentences in dat before and after keyword exclusion:'))
message(paste(length(unique(dat$Sentence))))
dat = dat %>%
  filter(!grepl(paste(exclusion_keywords, collapse = "|"), Sentence))
message(paste(length(unique(dat$Sentence))))

message(paste('num sentences in dat.human length before and after keyword exclusion:'))
message(paste(length(unique(dat.human$Sentence))))
dat.human = dat.human %>%
  filter(!grepl(paste(exclusion_keywords, collapse = "|"), Sentence))
message(paste(length(unique(dat.human$Sentence))))
```

# Save final dataframes
```{r}
savedir <- 'clean_data'

# main dataframe
filename <- paste('clean', experiment, 'df.csv', sep='_')
dat = dat %>% arrange(ItemNum,Metric,Voice,desc(Plausibility))
write.csv(dat, paste(savedir,filename,sep="/"), row.names = FALSE)

# sentence set
if (experiment=='EventsAdapt') {
  sentence_set = dat %>%
    select(ItemNum, Sentence, Plausibility, Voice, TrialType, SynonymPair, NumSyn) %>% 
    distinct() %>% arrange(ItemNum)
} else{
  sentence_set = dat %>%
    select(ItemNum, Sentence, Plausibility, Voice) %>% 
    distinct() %>% arrange(ItemNum)
}
filename <- paste('clean', experiment, 'SentenceSet.csv', sep='_')
write.csv(sentence_set, paste(savedir,filename,sep="/"), row.names = FALSE)

# human data
filename <- paste('clean', experiment, 'human_dat.csv', sep='_')
write.csv(dat.human %>% 
            filter(Sentence %in% shared_sentences) %>%
            arrange(ItemNum, desc(Plausibility)), 
          file=paste(savedir,filename,sep="/"))
```
